{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IRbLzk7bx27L"
      },
      "outputs": [],
      "source": [
        "# Hacemos un try except, para que si ya existe el recurso instalado, simplemente lo cargue y no lo instalemos sí o sí\n",
        "try:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  import pandas as pd\n",
        "  from google.cloud import storage\n",
        "except:\n",
        "  !pip install google-cloud-storage\n",
        "  !pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Estas funciones las podemos implementar en cada uno de nuestros notebooks\n",
        "# para hacer uso de un CSV y crear otro CSV, y todo ello contra los buckets\n",
        "# creados en el Google Cloud Storage de la arquitectura de la práctica\n",
        "#\n",
        "# Es muy importante tener permisos de Storage Object Creator, si no te deja\n",
        "# hacer nada, pide permiso al administrador\n",
        "#\n",
        "# El bucket de los csv de \"origen\" o no tratados será ds-edw-raw-d1655b14\n",
        "# El bucket de los csv \"finales\" o procesados será ds-edw-processed-d1655b14\n",
        "#\n",
        "\n",
        "\n",
        "# Descargamos el CSV con el que vamos a trabajar\n",
        "def descargar_de_bucket_origen(nombre_bucket_origen, nombre_blob_origen, nombre_archivo_destino):\n",
        "    cliente = storage.Client()\n",
        "    bucket = cliente.bucket(nombre_bucket_origen)\n",
        "    blob = bucket.blob(nombre_blob_origen)\n",
        "    blob.download_to_filename(nombre_archivo_destino)\n",
        "    print(f\"Archivo {nombre_blob_origen} descargado como {nombre_archivo_destino}.\")\n",
        "\n",
        "nombre_bucket_origen = 'ds-edw-raw-d1655b14'\n",
        "nombre_bucket_procesado = 'ds-edw-processed-d1655b14'\n",
        "nombre_blob_origen = 'dataset/hascosva_2022.csv' # Aquí se pone el nombre de la carpeta CSV, barra / , y el nombre del csv con el que queremos trabajar\n",
        "ruta_descarga_local = 'hascosva_2022.csv' # Aquí se pone solamente el nombre del csv con el que queremos trabajar\n",
        "descargar_de_bucket_origen(nombre_bucket_origen, nombre_blob_origen, ruta_descarga_local)\n",
        "\n",
        "# Trabajamos con el CSV y hacemos lo que haya que hacer con la fuente\n",
        "df = pd.read_csv(ruta_descarga_local)\n",
        "\n",
        "# Aquí haríamos los cambios que fuesen necesarios\n",
        "#  CODIGO\n",
        "#  CODIGO , etc\n",
        "\n",
        "# Una vez trabajado lo anterior, creamos nombre del fichero de destino y generamos dicho CSV\n",
        "csv_tratado = 'PonerCualquierNombre.csv'  # Acordaos de cambiar el nombre por el que corresponda\n",
        "df.to_csv(csv_tratado, index=False)\n",
        "\n",
        "# Subimos los cambios o tratamientos a un nuevo  bucket de procesados con un CSV nuevo\n",
        "def subir_a_bucket_destino(nombre_bucket_procesado, nombre_archivo_destino, nombre_blob_destino):\n",
        "    cliente = storage.Client()\n",
        "    bucket = cliente.bucket(nombre_bucket_procesado)\n",
        "    blob = bucket.blob(nombre_blob_destino)\n",
        "    # Verificar si el archivo ya existe en el bucket\n",
        "    if blob.exists():\n",
        "        print(f\"El archivo {nombre_blob_destino} ya existe en el bucket {nombre_bucket_procesado} y no se ha subido por no sobreescribirlo y preservar los datos, pon otro nombre o solicita ayuda al administrador del bucket.\")\n",
        "    else:\n",
        "        blob.upload_from_filename(nombre_archivo_destino)\n",
        "        print(f\"Archivo {nombre_archivo_destino} subido a {nombre_blob_destino} en el bucket {nombre_bucket_procesado}.\")\n",
        "\n",
        "nombre_blob_destino = 'CSV/PonerCualquierNombre.csv' # Acordaos de cambiar el nombre por el que corresponda\n",
        "subir_a_bucket_destino(nombre_bucket_procesado, csv_tratado, nombre_blob_destino)\n"
      ],
      "metadata": {
        "id": "5z6dGB-TyS4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf4905b-770d-45eb-9352-7ec134da206c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo dataset/hascosva_2022.csv descargado como hascosva_2022.csv.\n",
            "El archivo CSV/PonerCualquierNombre.csv ya existe en el bucket ds-edw-processed-d1655b14 y no se ha subido por no sobreescribirlo y preservar los datos, pon otro nombre o solicita ayuda al administrador del bucket.\n"
          ]
        }
      ]
    }
  ]
}